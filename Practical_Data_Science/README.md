# Practical Data Science
This set of projects uses applied methods of Data Science and Machine Learning to solve practical problems.

## üë©‚Äçüíª Project 1 - Human Annotator Analysis
The first part of this [ project ](https://github.com/FoivosM/Practical_Data_Science/blob/master/pd_A1_Annotation-Analysis.ipynb), 
involves a group of annotators that were given 100 proverbs to group into 50 categories at most, based on their subjective meaning. In order to quantify how reliable and reproducible the inferred groups are, we employ several exploratory methods to measure how much all the annotators agree with each other. The second part tries to identify the most challenging proverbs to classify, using effective visualization methods. Finally, we put Large Language Models (LLMs) to the test, by **prompting** them to cluster the given proverbs, and we close by presenting the associated challenges and interesting findings.

## üì∫ Project 2 - Crawling and Classifying Youtube Comments
This [ project ](https://github.com/FoivosM/Practical_Data_Science/blob/master/pd_A2_Crawling-and-classifying.ipynb) focuses on developing a RegExp-based language detector for Greek, Greeklish, English, and other languages. It involves crawling YouTube using **Selenium** and **BeautifulSoup** for Greek/Greeklish content, analyzing comments for language and toxicity levels. The process includes creating a ground truth dataset, analyzing crawled data, and applying a **toxicity classifier** to rate comments. In the last section, LLMs are prompted to act as sentiment-analysis classifiers, and are tested with the crawled data.

## üë©‚Äçüéì Project 3 - Detection of LLM Generated Texts
This project focuses on developing a model capable of **distinguishing between essays written by middle/high school students and those generated by LLMs**. Utilizing data from a [kaggle competition](https://www.kaggle.com/competitions/llm-detect-ai-generated-text), the process begins with *data exploration and augmentation*, where LLMs are prompted to generate essays to balance the dataset, and proceeds with the implementation of text classifiers to accurately identify if the author was a human or and AI. The process continues with further data exploration, analysis and *cleaning* to create a more robust dataset. Additionally, *learning curves* are analyzed to identify the model's performance over different training dataset sizes, and a clustering-based approach is adopted to further refine the data and improve classifier performance.
- [Notebook](https://github.com/FoivosM/Practical_Data_Science/blob/master/pd_A3_LLM-text-detection.ipynb)
- [Presentation](https://github.com/FoivosM/Practical_Data_Science/blob/master/pd_A3_LLM-text-detection_Report.pdf)
